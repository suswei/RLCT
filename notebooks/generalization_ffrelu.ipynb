{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalisation error\n",
    "\n",
    "In this experiment we vary the architecture of a feedforward ReLU network\n",
    "and examine the (average) Bayesian generalization error as a function over the architecture.\n",
    "\n",
    "We estimate the (average) Bayesian generalisation error as\n",
    "\\begin{equation}\n",
    "E_n B_g(n) \\approx E_n \\frac{1}{n'} \\sum_{i=1}^{n'} \\log \\frac{q(y_i|x_i)}{p(y_i |x_i,, \\mathcal D_n)}\n",
    "\\end{equation}\n",
    "where $\\mathcal D_n$ is the training set and $n'$ is the size of the test set.\n",
    "Note that the predictive distribution $p(y_i |x_i,, \\mathcal D_n)$ is with respect to inverse temperature $\\beta =1$\n",
    "\n",
    "To begin, we set some global parameters for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from main import *\n",
    "\n",
    "class Args:\n",
    "\n",
    "    dataset = 'ffrelu_synthetic'\n",
    "    sanity_check = True\n",
    "    syntheticsamplesize = 500\n",
    "\n",
    "    network = 'ffrelu'\n",
    "    VItype = 'implicit'\n",
    "    batchsize = 100\n",
    "    epochs = 200\n",
    "    epsilon_mc = 100\n",
    "    pretrainDepochs = 10\n",
    "    trainDepochs = 2\n",
    "    n_hidden_D = 50\n",
    "    num_hidden_layers_D = 2\n",
    "    n_hidden_G = 50\n",
    "    num_hidden_layers_G = 2\n",
    "\n",
    "    lr_primal = 1e-3\n",
    "    lr_dual = 5e-2\n",
    "\n",
    "    beta_auto_liberal = False\n",
    "    beta_auto_conservative = False\n",
    "    beta_auto_oracle = False\n",
    "    betasbegin = 0.1\n",
    "    betasend = 1.5\n",
    "    betalogscale = True\n",
    "    numbetas = 10\n",
    "\n",
    "    elasticnet_alpha = 1.0\n",
    "    R = 200\n",
    "\n",
    "    MCs = 10\n",
    "\n",
    "    log_interval = 50\n",
    "\n",
    "    cuda = False\n",
    "\n",
    "args = Args()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We design the true distribution to be realizable.\n",
    "In particular we generate univariate Gaussian (mean $0$ and variance $1$) input data $X$\n",
    "and set the univariate target $Y$ to be Gaussian with variance 1 and\n",
    "mean given by ```ffrelu```$(X,H_1=2,H_2=1)$ according to the following network\n",
    "\n",
    "```python\n",
    "class ffrelu(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim,H1,H2):\n",
    "        super(ffrelu, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, H1)\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.fc3 = nn.Linear(H2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "Below are some helper functions:\n",
    "- ```train``` outputs an estimate of the RLCT based on a grid of inverse temperatures $\\beta$\n",
    "- ```compute_predictive_dist``` takes in a generator trained on $D_n$ at $\\beta = 1$ and computes $p(y_i|x_i,D_n)$ by sampling\n",
    "- ```compute_Bg``` uses the result of ```compute_predictive_dist``` and the same testing dataset to compute $B_g = \\sum_{i=1}^{n'} \\log \\frac{q(y_i|x_i)}{p(y_i |x_i,, \\mathcal D_n)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% train implicit VI to get lambda estimate\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, valid_loader):\n",
    "\n",
    "    # get a grid of inverse temperatures [beta_1/log n, \\ldots, beta_k/log n]\n",
    "    set_betas(args)\n",
    "\n",
    "    mc = 1\n",
    "    saveimgpath = None\n",
    "    nll_betas_implicit = np.empty(0)\n",
    "\n",
    "    for beta_index in range(args.betas.shape[0]):\n",
    "\n",
    "        # train implicit variational inference\n",
    "        print('Begin training IVI')\n",
    "        G = train_implicitVI(train_loader, valid_loader, args, mc, beta_index, saveimgpath)\n",
    "        print('Finished training IVI')\n",
    "        nllw_array_implicit = approxinf_nll_implicit(train_loader, G, args)\n",
    "        nllw_mean_implicit = sum(nllw_array_implicit)/len(nllw_array_implicit)\n",
    "        nll_betas_implicit = np.append(nll_betas_implicit, nllw_mean_implicit)\n",
    "\n",
    "    ivi_robust, ivi_ols = lsfit_lambda(nll_betas_implicit, args, saveimgname=None)\n",
    "\n",
    "    return ivi_robust\n",
    "\n",
    "def compute_predictive_dist(args, G, loader):\n",
    "\n",
    "    R = 1000\n",
    "    eps = torch.randn(R, args.epsilon_dim)\n",
    "    sampled_weights = G(eps)\n",
    "    wholex = loader.dataset[:][0]\n",
    "    wholey = loader.dataset[:][1]\n",
    "    list_of_param_dicts = weights_to_dict(args, sampled_weights)\n",
    "\n",
    "    pred_logprob = 0\n",
    "    for param_dict in list_of_param_dicts:\n",
    "\n",
    "        h1 = F.relu((wholex @ param_dict['W1']) + param_dict['B1'])\n",
    "        h2 = F.relu((h1 @ param_dict['W2']) + param_dict['B2'])\n",
    "        mean = (h2 @ param_dict['W3']) + param_dict['B3']\n",
    "        pred_logprob += -(np.log(2 * np.pi) + (wholey - mean) ** 2) / 2\n",
    "\n",
    "    return pred_logprob/R\n",
    "\n",
    "\n",
    "def compute_Bg(pred_logprob,loader,args):\n",
    "\n",
    "    wholex = loader.dataset[:][0]\n",
    "    wholey = loader.dataset[:][1]\n",
    "    true_logprob = -(np.log(2 * np.pi) + (wholey - args.true_mean(wholex)) ** 2) / 2\n",
    "\n",
    "    return (true_logprob-pred_logprob).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We range over the model's architecture as determined by $H_1$ and $H_2$.\n",
    "For each architecture we estimate the RLCT and calculate the average Bayesian generalization error.\n",
    "Hopefully we can see the relationship $E_n B_g(n) \\approx \\lambda/n$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Calculate average Bayesian generalisation error and RLCT estimate as H1, H2 varies in model\n"
    }
   },
   "outputs": [],
   "source": [
    "args.input_dim = 1\n",
    "args.output_dim = 1\n",
    "args.true_mean = models.ffrelu(args.input_dim, args.output_dim, 2, 1)\n",
    "\n",
    "H1range = range(1,4)\n",
    "H2range = range(1,3)\n",
    "results = []\n",
    "\n",
    "for H1 in H1range:\n",
    "    for H2 in H2range:\n",
    "\n",
    "        args.H1 = H1\n",
    "        args.H2 = H2\n",
    "        args.model, args.w_dim = retrieve_model(args)\n",
    "        args.epsilon_dim = args.w_dim\n",
    "\n",
    "        Bg = np.empty(args.MCs)\n",
    "        rlct = np.empty(args.MCs)\n",
    "\n",
    "        for mc in range(0,args.MCs):\n",
    "\n",
    "            train_loader, valid_loader, test_loader = get_dataset_by_id(args, kwargs)\n",
    "\n",
    "            args.betas = [1.0]\n",
    "            beta_index = 0\n",
    "            G = train_implicitVI(train_loader, valid_loader, args, mc, beta_index, saveimgpath=None)\n",
    "            pred = compute_predictive_dist(args, G, test_loader)\n",
    "            Bg[mc] = compute_Bg(pred,test_loader,args)\n",
    "\n",
    "            rlct[mc] = train(args, train_loader, valid_loader)\n",
    "\n",
    "        print('H1: {}, H2: {}'.format(H1,H2))\n",
    "        print('E_n Bg(n): {}'.format(Bg.mean()))\n",
    "        print('hat RLCT/n: {}'.format(rlct.mean()/args.syntheticsamplesize))\n",
    "        results += {'H1':H1, 'H2':H2, 'E_n Bg(n)': Bg.mean(), 'hat RLCT/n': rlct.mean()/ args.syntheticsamplesize}\n",
    "\n",
    "\n",
    "with open('generalization_ffrelu.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}